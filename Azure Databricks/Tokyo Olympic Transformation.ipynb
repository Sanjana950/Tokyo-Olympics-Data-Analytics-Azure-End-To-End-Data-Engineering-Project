{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0db0b2ee-f244-45e2-9591-6862ef31e9a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client_id = dbutils.secrets.get(scope=\"scopeClientID\", key=\"secretClientID\")\n",
    "secret_key = dbutils.secrets.get(scope=\"scopeSecretKey\", key=\"secretSecretKey\")\n",
    "tenant_id = dbutils.secrets.get(scope=\"scopeTenantID\", key=\"secretTenantID\")\n",
    "\n",
    "configs = {\n",
    "    \"fs.azure.account.auth.type\": \"OAuth\",\n",
    "    \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "    \"fs.azure.account.oauth2.client.id\": client_id,\n",
    "    \"fs.azure.account.oauth2.client.secret\": secret_key,\n",
    "    \"fs.azure.account.oauth2.client.endpoint\": f\"https://login.microsoftonline.com/{tenant_id.strip()}/oauth2/token\"\n",
    "}\n",
    "\n",
    "source = \"abfss://tokyo-olympic-data@tokyoolympicdata1sanjana.dfs.core.windows.net/\"\n",
    "mount_point = \"/mnt/tokyoolympic\"\n",
    "\n",
    "dbutils.fs.mount(\n",
    "    source=source,\n",
    "    mount_point=mount_point,\n",
    "    extra_configs=configs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2cee7ac-5133-46d3-928c-7825ed21a4a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs\n",
    "ls mnt/tokyoolympic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f9db0dc-baed-4b24-8d05-fe7ba65cbd10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs\n",
    "ls mnt/tokyoolympic/raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1fe75e8-dd98-4cd1-8244-874e12b6967e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Tokyo Olmpics Transformation\n",
    "**\"Athletes Participation\" Transformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9767ddaa-94b8-41db-89a6-9ba5c97b712e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Load the athletes table from the mounted Parquet path\n",
    "athletes_path = \"/mnt/tokyoolympic/raw_data/athletes.csv\"\n",
    "athletes_df = spark.read.format(\"csv\").option(\"Header\", True).load(athletes_path)\n",
    "\n",
    "# Transformation 1: Count athletes grouped by NOC and Discipline\n",
    "athletes_summary = athletes_df.groupBy(\"Country\", \"Discipline\").agg(\n",
    "    countDistinct(\"PersonName\").alias(\"TotalAthletes\")\n",
    ")\n",
    "\n",
    "# Transformation 2: Get distinct athletes with their NOC and Discipline\n",
    "distinct_athletes = athletes_df.select(\"PersonName\", \"Country\", \"Discipline\").distinct()\n",
    "\n",
    "# Save the transformed data back to ADLS\n",
    "athletes_summary_path = \"/mnt/tokyoolympic/transformed_data/athletes_summary\"\n",
    "distinct_athletes_path = \"/mnt/tokyoolympic/transformed_data/distinct_athletes\"\n",
    "\n",
    "athletes_summary.write.format(\"parquet\").mode(\"overwrite\").save(athletes_summary_path)\n",
    "distinct_athletes.write.format(\"parquet\").mode(\"overwrite\").save(distinct_athletes_path)\n",
    "\n",
    "# Display the results\n",
    "athletes_summary.show()\n",
    "distinct_athletes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bafe710f-2c2c-4b0a-b6aa-5973d37ae70f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**\"Medal Overview\" Transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "161b42d5-259a-4bf4-bd3e-bb649b92ed08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum as _sum, rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Create Spark session (if not already created)\n",
    "spark = SparkSession.builder.appName(\"TokyoOlympics\").getOrCreate()\n",
    "\n",
    "# Load the medals table from the mounted Parquet path\n",
    "medals_path = \"/mnt/tokyoolympic/raw_data/medals.csv\"\n",
    "medals_df = spark.read.format(\"csv\").option(\"header\",True).load(medals_path)\n",
    "medals_df.show()\n",
    "# Transformation 1: Aggregate medal counts by TeamNOC\n",
    "medals_summary = medals_df.groupBy(\"TeamCountry\").agg(\n",
    "    _sum(\"Gold\").alias(\"TotalGold\"),\n",
    "    _sum(\"Silver\").alias(\"TotalSilver\"),\n",
    "    _sum(\"Bronze\").alias(\"TotalBronze\"),\n",
    "    _sum(\"Total\").alias(\"TotalMedals\")\n",
    ")\n",
    "\n",
    "# Transformation 2: Rank countries by Total Medals and Gold Medals\n",
    "windowSpecTotal = Window.orderBy(col(\"TotalMedals\").desc())\n",
    "windowSpecGold = Window.orderBy(col(\"TotalGold\").desc())\n",
    "\n",
    "ranked_medals = medals_summary.withColumn(\"RankByTotalMedals\", rank().over(windowSpecTotal)) \\\n",
    "                               .withColumn(\"RankByGoldMedals\", rank().over(windowSpecGold))\n",
    "\n",
    "# Save the transformed data back to a Parquet file in ADLS\n",
    "output_path = \"/mnt/tokyoolympic/transformed_data/medals_summary\"\n",
    "ranked_medals.write.format(\"parquet\").mode(\"overwrite\").save(output_path)\n",
    "\n",
    "# Display the final DataFrame\n",
    "ranked_medals.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e09ea3e-8afb-40a4-9879-263715234a0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**\"Gender Distribution\" Transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae856712-0c11-4a8a-a54c-0837675267d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "# Load the entriesgender table from the mounted Parquet path\n",
    "entriesgender_path = \"/mnt/tokyoolympic/raw_data/entriesgender.csv\"\n",
    "entriesgender_df = spark.read.format(\"csv\").option(\"header\",True).load(entriesgender_path)\n",
    "\n",
    "# Transformation 1: Aggregate gender-wise participation by Discipline\n",
    "gender_summary = entriesgender_df.select(\"Discipline\",\n",
    "    col(\"Female\").cast(\"int\").alias(\"FemaleParticipants\"),\n",
    "    col(\"Male\").cast(\"int\").alias(\"MaleParticipants\"),\n",
    "    col(\"Total\").cast(\"int\").alias(\"TotalParticipants\")\n",
    ")\n",
    "\n",
    "# Transformation 2: Calculate gender ratio (Female and Male percentage)\n",
    "gender_ratio = gender_summary.withColumn(\n",
    "    \"FemalePercentage\", expr(\"ROUND((FemaleParticipants / TotalParticipants) * 100, 2)\")\n",
    ").withColumn(\n",
    "    \"MalePercentage\", expr(\"ROUND((MaleParticipants / TotalParticipants) * 100, 2)\")\n",
    ")\n",
    "\n",
    "# Save the transformed data back to ADLS\n",
    "gender_summary_path = \"/mnt/tokyo-olympics-data/transformed_data/gender_summary\"\n",
    "\n",
    "gender_ratio.write.format(\"parquet\").mode(\"overwrite\").save(gender_summary_path)\n",
    "\n",
    "# Display the results\n",
    "gender_ratio.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "949c5373-c8a0-4922-bae5-4bba45258da4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**\"Event Insights\" Transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "550bfb0c-e1e9-45d7-b918-ef0bec8fbaeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Load the teams table from the mounted Parquet path\n",
    "teams_path = \"/mnt/tokyoolympic/raw_data/teams.csv\"\n",
    "teams_df = spark.read.format(\"csv\").option(\"header\",True).load(teams_path)\n",
    "\n",
    "# Transformation 1: Count unique events grouped by NOC and Discipline\n",
    "events_summary = teams_df.groupBy(\"Country\", \"Discipline\").agg(\n",
    "    countDistinct(\"Event\").alias(\"UniqueEventCount\")\n",
    ")\n",
    "\n",
    "# Transformation 2: Get a distinct list of events for detailed analysis\n",
    "distinct_events = teams_df.select(\"Event\", \"Country\", \"Discipline\").distinct()\n",
    "\n",
    "# Save the transformed data back to ADLS\n",
    "events_summary_path = \"/mnt/tokyoolympic/transformed_data/events_summary\"\n",
    "distinct_events_path = \"/mnt/tokyoolympic/transformed_data/distinct_events\"\n",
    "\n",
    "events_summary.write.format(\"parquet\").mode(\"overwrite\").save(events_summary_path)\n",
    "distinct_events.write.format(\"parquet\").mode(\"overwrite\").save(distinct_events_path)\n",
    "\n",
    "# Display the results\n",
    "events_summary.show(truncate=False)\n",
    "distinct_events.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96904380-da71-47fc-937d-c11e2b842bac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**\"Top Countries and Rankings\" Transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e5575b7-8d7e-4f43-a8b3-b60b26b7fe0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, expr, rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Load the medals table from the mounted Parquet path\n",
    "medals_path = \"/mnt/tokyoolympic/raw_data/medals.csv\"\n",
    "medals_df = spark.read.format(\"csv\").option(\"header\",True).load(medals_path)\n",
    "\n",
    "# Transformation 1: Add percentages for Gold, Silver, and Bronze medals\n",
    "medals_with_percentages = medals_df.withColumn(\n",
    "    \"GoldPercentage\", expr(\"ROUND((Gold / Total) * 100, 2)\")\n",
    ").withColumn(\n",
    "    \"SilverPercentage\", expr(\"ROUND((Silver / Total) * 100, 2)\")\n",
    ").withColumn(\n",
    "    \"BronzePercentage\", expr(\"ROUND((Bronze / Total) * 100, 2)\")\n",
    ")\n",
    "\n",
    "# Transformation 2: Rank countries by Total Medals and Gold Medals\n",
    "windowSpecTotal = Window.orderBy(col(\"Total\").desc())\n",
    "windowSpecGold = Window.orderBy(col(\"Gold\").desc())\n",
    "\n",
    "ranked_countries = medals_with_percentages.withColumn(\n",
    "    \"RankByTotal\", rank().over(windowSpecTotal)\n",
    ").withColumn(\n",
    "    \"RankByGold\", rank().over(windowSpecGold)\n",
    ")\n",
    "\n",
    "# Transformation 3: Filter top 10 countries by total medals\n",
    "top_10_countries = ranked_countries.filter(col(\"RankByTotal\") <= 10)\n",
    "\n",
    "# Save the transformed data back to ADLS\n",
    "ranked_countries_path = \"/mnt/tokyoolympic/transformed_data/ranked_countries\"\n",
    "top_10_countries_path = \"/mnt/tokyoolympic/transformed_data/top_10_countries\"\n",
    "\n",
    "ranked_countries.write.format(\"parquet\").mode(\"overwrite\").save(ranked_countries_path)\n",
    "top_10_countries.write.format(\"parquet\").mode(\"overwrite\").save(top_10_countries_path)\n",
    "\n",
    "# Display the results\n",
    "ranked_countries.show()\n",
    "top_10_countries.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "690a3c2b-382e-49c9-b628-282c7cd6d085",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**\"Athlete Highlights\" Transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a29b254-8910-4db8-b5a8-aa2fcb0f5017",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, count, sum as _sum, rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Load the athletes and medals tables\n",
    "athletes_path = \"/mnt/tokyoolympic/raw_data/athletes.csv\"\n",
    "medals_path = \"/mnt/tokyoolympic/raw_data/medals.csv\"\n",
    "\n",
    "athletes_df = spark.read.format(\"csv\").option(\"header\",True).load(athletes_path)\n",
    "medals_df = spark.read.format(\"csv\").option(\"header\",True).load(medals_path)\n",
    "\n",
    "# Transformation 1: Join athletes with medals data on NOC\n",
    "athletes_with_medals = athletes_df.join(\n",
    "    medals_df,\n",
    "    athletes_df.Country == medals_df.TeamCountry,\n",
    "    how=\"left\"\n",
    ").select(\n",
    "    col(\"PersonName\"),\n",
    "    col(\"Country\"),\n",
    "    col(\"Discipline\"),\n",
    "    col(\"Gold\"),\n",
    "    col(\"Silver\"),\n",
    "    col(\"Bronze\"),\n",
    "    col(\"Total\")\n",
    ")\n",
    "\n",
    "# Transformation 2: Aggregate top-performing athletes by NOC and Discipline\n",
    "top_athletes = athletes_with_medals.groupBy(\"Country\", \"Discipline\").agg(\n",
    "    count(\"PersonName\").alias(\"TotalAthletes\"),\n",
    "    _sum(\"Gold\").alias(\"TotalGold\"),\n",
    "    _sum(\"Silver\").alias(\"TotalSilver\"),\n",
    "    _sum(\"Bronze\").alias(\"TotalBronze\"),\n",
    "    _sum(\"Total\").alias(\"TotalMedals\")\n",
    ")\n",
    "\n",
    "# Transformation 3: Rank disciplines within each NOC by total medals\n",
    "windowSpec = Window.partitionBy(\"Country\").orderBy(col(\"TotalMedals\").desc())\n",
    "ranked_athletes = top_athletes.withColumn(\"RankByMedals\", rank().over(windowSpec))\n",
    "\n",
    "# Save the transformed data back to ADLS\n",
    "athletes_with_medals_path = \"/mnt/tokyoolympic/transformed_data/athletes_with_medals\"\n",
    "ranked_athletes_path = \"/mnt/tokyoolympic/transformed_data/ranked_athletes\"\n",
    "\n",
    "athletes_with_medals.write.format(\"parquet\").mode(\"overwrite\").save(athletes_with_medals_path)\n",
    "ranked_athletes.write.format(\"parquet\").mode(\"overwrite\").save(ranked_athletes_path)\n",
    "\n",
    "# Display the results\n",
    "athletes_with_medals.show()\n",
    "ranked_athletes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e90b25f7-852b-42fa-a66d-4e6a1c13488c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**\"Discipline Insights\" Transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ebce8a5-59e6-4e40-9e4d-0febcd1fb07b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum, expr, rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Load the athletes and entriesgender tables\n",
    "athletes_path = \"/mnt/tokyoolympic/raw_data/athletes.csv\"\n",
    "entriesgender_path = \"/mnt/tokyoolympic/raw_data/entriesgender.csv\"\n",
    "\n",
    "athletes_df = spark.read.format(\"csv\").option(\"header\",True).load(athletes_path)\n",
    "entriesgender_df = spark.read.format(\"csv\").option(\"header\",True).load(entriesgender_path)\n",
    "\n",
    "# Transformation 1: Calculate the total number of athletes per discipline\n",
    "discipline_athletes = athletes_df.groupBy(\"Discipline\").agg(\n",
    "    _sum(expr(\"1\")).alias(\"TotalAthletes\")\n",
    ")\n",
    "\n",
    "# Transformation 2: Combine with gender distribution data\n",
    "discipline_insights = discipline_athletes.join(\n",
    "    entriesgender_df,\n",
    "    \"Discipline\",\n",
    "    how=\"inner\"\n",
    ").select(\n",
    "    col(\"Discipline\"),\n",
    "    col(\"TotalAthletes\"),\n",
    "    col(\"Female\").cast(\"int\").alias(\"FemaleParticipants\"),\n",
    "    col(\"Male\").cast(\"int\").alias(\"MaleParticipants\"),\n",
    "    col(\"Total\").cast(\"int\").alias(\"TotalParticipants\")\n",
    ").withColumn(\n",
    "    \"FemalePercentage\", expr(\"ROUND((FemaleParticipants / TotalParticipants) * 100, 2)\")\n",
    ").withColumn(\n",
    "    \"MalePercentage\", expr(\"ROUND((MaleParticipants / TotalParticipants) * 100, 2)\")\n",
    ")\n",
    "\n",
    "# Transformation 3: Rank disciplines by total participation and female percentage\n",
    "windowSpecTotal = Window.orderBy(col(\"TotalParticipants\").desc())\n",
    "windowSpecFemale = Window.orderBy(col(\"FemalePercentage\").desc())\n",
    "\n",
    "ranked_disciplines = discipline_insights.withColumn(\n",
    "    \"RankByTotalParticipants\", rank().over(windowSpecTotal)\n",
    ").withColumn(\n",
    "    \"RankByFemalePercentage\", rank().over(windowSpecFemale)\n",
    ")\n",
    "\n",
    "# Save the transformed data back to ADLS\n",
    "discipline_insights_path = \"/mnt/tokyoolympic/transformed_data/discipline_insights\"\n",
    "ranked_disciplines_path = \"/mnt/tokyoolympic/transformed_data/ranked_disciplines\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fec35a45-94b5-4a14-948f-d92e59c0e362",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**\"Country Level Performance Insights\" Transformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afab8e31-77d2-460c-87ad-f60ab307dc0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, sum as _sum, expr, rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Load the athletes and medals tables\n",
    "athletes_path = \"/mnt/tokyoolympic/raw_data/athletes.csv\"\n",
    "medals_path = \"/mnt/tokyoolympic/raw_data/medals.csv\"\n",
    "\n",
    "athletes_df = spark.read.format(\"csv\").option(\"header\",True).load(athletes_path)\n",
    "medals_df = spark.read.format(\"csv\").option(\"header\",True).load(medals_path)\n",
    "\n",
    "# Transformation 1: Calculate total number of athletes per country\n",
    "country_athletes = athletes_df.groupBy(\"Country\").agg(\n",
    "    count(\"PersonName\").alias(\"TotalAthletes\")\n",
    ")\n",
    "\n",
    "# Transformation 2: Merge medals data with athlete counts\n",
    "country_performance = medals_df.join(\n",
    "    country_athletes,\n",
    "    medals_df.TeamCountry == country_athletes.Country,\n",
    "    how=\"inner\"\n",
    ").select(\n",
    "    col(\"TeamCountry\").alias(\"Country\"),\n",
    "    col(\"TotalAthletes\"),\n",
    "    col(\"Gold\"),\n",
    "    col(\"Silver\"),\n",
    "    col(\"Bronze\"),\n",
    "    col(\"Total\").alias(\"TotalMedals\")\n",
    ")\n",
    "\n",
    "# Transformation 3: Calculate average medals per athlete\n",
    "country_performance = country_performance.withColumn(\n",
    "    \"AvgMedalsPerAthlete\", expr(\"ROUND(TotalMedals / TotalAthletes, 2)\")\n",
    ")\n",
    "\n",
    "# Transformation 4: Rank countries based on total medals and average medals per athlete\n",
    "windowSpecTotal = Window.orderBy(col(\"TotalMedals\").desc())\n",
    "windowSpecAvg = Window.orderBy(col(\"AvgMedalsPerAthlete\").desc())\n",
    "\n",
    "ranked_countries = country_performance.withColumn(\n",
    "    \"RankByTotalMedals\", rank().over(windowSpecTotal)\n",
    ").withColumn(\n",
    "    \"RankByAvgMedalsPerAthlete\", rank().over(windowSpecAvg)\n",
    ")\n",
    "\n",
    "# Save the transformed data back to ADLS\n",
    "country_performance_path = \"/mnt/tokyoolympic/transformed_data/country_performance\"\n",
    "ranked_countries_path = \"/mnt/tokyoolympic/transformed_data/ranked_countries_performance\"\n",
    "\n",
    "country_performance.write.format(\"parquet\").mode(\"overwrite\").save(country_performance_path)\n",
    "ranked_countries.write.format(\"parquet\").mode(\"overwrite\").save(ranked_countries_path)\n",
    "\n",
    "# Display the results\n",
    "country_performance.show()\n",
    "ranked_countries.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a82d2b34-a0af-45c7-b6ec-c199da097639",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**\"Medal Trends by Discipline and Country\" Transformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c50f18f-3490-4eaa-b445-9df326289c39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum, rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Load the medals and teams tables\n",
    "medals_path = \"/mnt/tokyoolympic/raw_data/medals.csv\"\n",
    "teams_path = \"/mnt/tokyoolympic/raw_data/teams.csv\"\n",
    "\n",
    "medals_df = spark.read.format(\"csv\").option(\"header\",True).load(medals_path)\n",
    "teams_df = spark.read.format(\"csv\").option(\"header\",True).load(teams_path)\n",
    "\n",
    "# Transformation 1: Join medals data with teams to associate disciplines with medals\n",
    "medals_by_discipline = medals_df.join(\n",
    "    teams_df,\n",
    "    medals_df.TeamCountry == teams_df.Country,\n",
    "    how=\"inner\"\n",
    ").select(\n",
    "    col(\"TeamCountry\").alias(\"Country\"),\n",
    "    col(\"Discipline\"),\n",
    "    col(\"Gold\"),\n",
    "    col(\"Silver\"),\n",
    "    col(\"Bronze\"),\n",
    "    col(\"Total\").alias(\"TotalMedals\")\n",
    ")\n",
    "\n",
    "# Transformation 2: Calculate total medals by discipline and NOC\n",
    "discipline_medals = medals_by_discipline.groupBy(\"Country\", \"Discipline\").agg(\n",
    "    _sum(\"Gold\").alias(\"TotalGold\"),\n",
    "    _sum(\"Silver\").alias(\"TotalSilver\"),\n",
    "    _sum(\"Bronze\").alias(\"TotalBronze\"),\n",
    "    _sum(\"TotalMedals\").alias(\"TotalMedalsByDiscipline\")\n",
    ")\n",
    "\n",
    "# Transformation 3: Rank disciplines within each country by total medals\n",
    "windowSpec = Window.partitionBy(\"Country\").orderBy(col(\"TotalMedalsByDiscipline\").desc())\n",
    "\n",
    "ranked_disciplines_by_country = discipline_medals.withColumn(\n",
    "    \"RankByDiscipline\", rank().over(windowSpec)\n",
    ")\n",
    "\n",
    "# Save the transformed data back to ADLS\n",
    "discipline_medals_path = \"/mnt/tokyoolympic/transformed_data/discipline_medals\"\n",
    "ranked_disciplines_path = \"/mnt/tokyoolympic/transformed_data/ranked_disciplines_by_country\"\n",
    "\n",
    "discipline_medals.write.format(\"parquet\").mode(\"overwrite\").save(discipline_medals_path)\n",
    "ranked_disciplines_by_country.write.format(\"parquet\").mode(\"overwrite\").save(ranked_disciplines_path)\n",
    "\n",
    "# Display the results\n",
    "discipline_medals.show()\n",
    "ranked_disciplines_by_country.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ea855e7-fbe8-4c5f-8e82-7e979c148252",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**\"Event Participation Insights\" Transformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c22784a-b950-4d2f-bbed-e16234791b74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, countDistinct, rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Load the teams and entriesgender tables\n",
    "teams_path = \"/mnt/tokyoolympic/raw_data/teams.csv\"\n",
    "entriesgender_path = \"/mnt/tokyoolympic/raw_data/entriesgender.csv\"\n",
    "\n",
    "teams_df = spark.read.format(\"csv\").option(\"header\",True).load(teams_path)\n",
    "entriesgender_df = spark.read.format(\"csv\").option(\"header\",True).load(entriesgender_path)\n",
    "\n",
    "# Transformation 1: Calculate total number of events grouped by NOC and Discipline\n",
    "event_summary = teams_df.groupBy(\"Country\", \"Discipline\").agg(\n",
    "    countDistinct(\"Event\").alias(\"TotalEvents\")\n",
    ")\n",
    "\n",
    "# Transformation 2: Combine with gender distribution data\n",
    "event_participation = event_summary.join(\n",
    "    entriesgender_df,\n",
    "    \"Discipline\",\n",
    "    how=\"inner\"\n",
    ").select(\n",
    "    col(\"Country\"),\n",
    "    col(\"Discipline\"),\n",
    "    col(\"TotalEvents\"),\n",
    "    col(\"Female\").cast(\"int\").alias(\"FemaleParticipants\"),\n",
    "    col(\"Male\").cast(\"int\").alias(\"MaleParticipants\"),\n",
    "    col(\"Total\").cast(\"int\").alias(\"TotalParticipants\")\n",
    ")\n",
    "\n",
    "# Transformation 3: Rank disciplines within each NOC by event participation\n",
    "windowSpec = Window.partitionBy(\"Country\").orderBy(col(\"TotalEvents\").desc())\n",
    "\n",
    "ranked_event_participation = event_participation.withColumn(\n",
    "    \"RankByEvents\", rank().over(windowSpec)\n",
    ")\n",
    "\n",
    "# Save the transformed data back to ADLS\n",
    "event_summary_path = \"/mnt/tokyoolympic/transformed_data/event_summary\"\n",
    "ranked_event_participation_path = \"/mnt/tokyoolympic/transformed_data/ranked_event_participation\"\n",
    "\n",
    "event_participation.write.format(\"parquet\").mode(\"overwrite\").save(event_summary_path)\n",
    "ranked_event_participation.write.format(\"parquet\").mode(\"overwrite\").save(ranked_event_participation_path)\n",
    "\n",
    "# Display the results\n",
    "event_participation.show()\n",
    "ranked_event_participation.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "641da2d0-08d2-44a2-aa26-60f7230d6318",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**\"Comprehensive Medal and Athlete Analysis\" Transformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74c4600f-8e90-4063-931b-2e8e1d64482d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, sum as _sum, expr, rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Load the medals and athletes tables\n",
    "medals_path = \"/mnt/tokyoolympic/raw_data/medals.csv\"\n",
    "athletes_path = \"/mnt/tokyoolympic/raw_data/athletes.csv\"\n",
    "\n",
    "medals_df = spark.read.format(\"csv\").option(\"header\",True).load(medals_path)\n",
    "athletes_df = spark.read.format(\"csv\").option(\"header\",True).load(athletes_path)\n",
    "\n",
    "# Transformation 1: Calculate total number of athletes per country\n",
    "country_athletes = athletes_df.groupBy(\"Country\").agg(\n",
    "    count(\"PersonName\").alias(\"TotalAthletes\")\n",
    ")\n",
    "\n",
    "# Transformation 2: Combine medals and athlete data\n",
    "medal_athlete_analysis = medals_df.join(\n",
    "    country_athletes,\n",
    "    medals_df.TeamCountry == country_athletes.Country,\n",
    "    how=\"inner\"\n",
    ").select(\n",
    "    col(\"TeamCountry\").alias(\"Country\"),\n",
    "    col(\"TotalAthletes\"),\n",
    "    col(\"Gold\"),\n",
    "    col(\"Silver\"),\n",
    "    col(\"Bronze\"),\n",
    "    col(\"Total\").alias(\"TotalMedals\")\n",
    ").withColumn(\n",
    "    \"MedalsPerAthlete\", expr(\"ROUND(TotalMedals / TotalAthletes, 2)\")\n",
    ")\n",
    "\n",
    "# Transformation 3: Rank countries based on medal efficiency\n",
    "windowSpecEfficiency = Window.orderBy(col(\"MedalsPerAthlete\").desc())\n",
    "\n",
    "ranked_medal_efficiency = medal_athlete_analysis.withColumn(\n",
    "    \"RankByEfficiency\", rank().over(windowSpecEfficiency)\n",
    ")\n",
    "\n",
    "# Save the transformed data back to ADLS\n",
    "medal_athlete_analysis_path = \"/mnt/tokyoolympic/transformed_data/medal_athlete_analysis\"\n",
    "ranked_medal_efficiency_path = \"/mnt/tokyoolympic/transformed_data/ranked_medal_efficiency\"\n",
    "\n",
    "medal_athlete_analysis.write.format(\"parquet\").mode(\"overwrite\").save(medal_athlete_analysis_path)\n",
    "ranked_medal_efficiency.write.format(\"parquet\").mode(\"overwrite\").save(ranked_medal_efficiency_path)\n",
    "\n",
    "# Display the results\n",
    "medal_athlete_analysis.show()\n",
    "ranked_medal_efficiency.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "306ebe03-e29c-4534-b815-2898d9dd4886",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**\"Discipline-Level Gender and Medal Insights\" Transformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fd6b8e2-40d5-4660-8e7e-127c6e114066",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum, expr, rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Load the required tables\n",
    "entriesgender_path = \"/mnt/tokyoolympic/raw_data/entriesgender.csv\"\n",
    "medals_path = \"/mnt/tokyoolympic/raw_data/medals.csv\"\n",
    "teams_path = \"/mnt/tokyoolympic/raw_data/teams.csv\"\n",
    "\n",
    "entriesgender_df = spark.read.format(\"csv\").option(\"header\",True).load(entriesgender_path)\n",
    "medals_df = spark.read.format(\"csv\").option(\"header\",True).load(medals_path)\n",
    "teams_df = spark.read.format(\"csv\").option(\"header\",True).load(teams_path)\n",
    "\n",
    "# Transformation 1: Aggregate total medals by Discipline\n",
    "medals_by_discipline = medals_df.join(\n",
    "    teams_df,\n",
    "    medals_df.TeamCountry == teams_df.Country,\n",
    "    how=\"inner\"\n",
    ").groupBy(\"Discipline\").agg(\n",
    "    _sum(\"Gold\").alias(\"TotalGold\"),\n",
    "    _sum(\"Silver\").alias(\"TotalSilver\"),\n",
    "    _sum(\"Bronze\").alias(\"TotalBronze\"),\n",
    "    _sum(\"Total\").alias(\"TotalMedals\")\n",
    ")\n",
    "\n",
    "# Transformation 2: Combine gender participation with medal data\n",
    "discipline_gender_medals = medals_by_discipline.join(\n",
    "    entriesgender_df,\n",
    "    \"Discipline\",\n",
    "    how=\"inner\"\n",
    ").select(\n",
    "    col(\"Discipline\"),\n",
    "    col(\"TotalGold\"),\n",
    "    col(\"TotalSilver\"),\n",
    "    col(\"TotalBronze\"),\n",
    "    col(\"TotalMedals\"),\n",
    "    col(\"Female\").cast(\"int\").alias(\"FemaleParticipants\"),\n",
    "    col(\"Male\").cast(\"int\").alias(\"MaleParticipants\"),\n",
    "    col(\"Total\").cast(\"int\").alias(\"TotalParticipants\")\n",
    ").withColumn(\n",
    "    \"FemalePercentage\", expr(\"ROUND((FemaleParticipants / TotalParticipants) * 100, 2)\")\n",
    ").withColumn(\n",
    "    \"MalePercentage\", expr(\"ROUND((MaleParticipants / TotalParticipants) * 100, 2)\")\n",
    ")\n",
    "\n",
    "# Transformation 3: Rank disciplines by total medals and gender balance\n",
    "windowSpecMedals = Window.orderBy(col(\"TotalMedals\").desc())\n",
    "windowSpecFemale = Window.orderBy(col(\"FemalePercentage\").desc())\n",
    "\n",
    "ranked_discipline_gender = discipline_gender_medals.withColumn(\n",
    "    \"RankByMedals\", rank().over(windowSpecMedals)\n",
    ").withColumn(\n",
    "    \"RankByFemaleParticipation\", rank().over(windowSpecFemale)\n",
    ")\n",
    "\n",
    "# Save the transformed data back to ADLS\n",
    "discipline_gender_medals_path = \"/mnt/tokyoolympic/transformed_data/discipline_gender_medals\"\n",
    "ranked_discipline_gender_path = \"/mnt/tokyoolympic/transformed_data/ranked_discipline_gender\"\n",
    "\n",
    "discipline_gender_medals.write.format(\"parquet\").mode(\"overwrite\").save(discipline_gender_medals_path)\n",
    "ranked_discipline_gender.write.format(\"parquet\").mode(\"overwrite\").save(ranked_discipline_gender_path)\n",
    "\n",
    "# Display the results\n",
    "discipline_gender_medals.show()\n",
    "ranked_discipline_gender.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca38cf25-ee5f-4322-b696-16d6c600094b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Continent Mapping DataFrame Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54f691cb-021f-4fe5-8397-49400136b881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark session if not already created\n",
    "spark = SparkSession.builder.appName(\"ContinentMapping\").getOrCreate()\n",
    "\n",
    "# Define the continent mapping manually\n",
    "continent_data = [\n",
    "    (\"United States of America\", \"North America\"),\n",
    "    (\"People's Republic of China\", \"Asia\"),\n",
    "    (\"Japan\", \"Asia\"),\n",
    "    (\"Great Britain\", \"Europe\"),\n",
    "    (\"ROC\", \"Europe\"),\n",
    "    (\"Australia\", \"Oceania\"),\n",
    "    (\"Netherlands\", \"Europe\"),\n",
    "    (\"France\", \"Europe\"),\n",
    "    (\"Germany\", \"Europe\"),\n",
    "    (\"Italy\", \"Europe\"),\n",
    "    (\"Canada\", \"North America\"),\n",
    "    (\"Brazil\", \"South America\"),\n",
    "    (\"New Zealand\", \"Oceania\"),\n",
    "    (\"Cuba\", \"North America\"),\n",
    "    (\"Hungary\", \"Europe\"),\n",
    "    (\"Republic of Korea\", \"Asia\"),\n",
    "    (\"Poland\", \"Europe\"),\n",
    "    (\"Czech Republic\", \"Europe\"),\n",
    "    (\"Kenya\", \"Africa\"),\n",
    "    (\"Norway\", \"Europe\"),\n",
    "    (\"Jamaica\", \"North America\"),\n",
    "    (\"Spain\", \"Europe\"),\n",
    "    (\"Sweden\", \"Europe\"),\n",
    "    (\"Switzerland\", \"Europe\"),\n",
    "    (\"Denmark\", \"Europe\"),\n",
    "    (\"Croatia\", \"Europe\"),\n",
    "    (\"Islamic Republic of Iran\", \"Asia\"),\n",
    "    (\"Serbia\", \"Europe\"),\n",
    "    (\"Belgium\", \"Europe\"),\n",
    "    (\"Bulgaria\", \"Europe\"),\n",
    "    (\"Slovenia\", \"Europe\"),\n",
    "    (\"Uzbekistan\", \"Asia\"),\n",
    "    (\"Georgia\", \"Asia\"),\n",
    "    (\"Chinese Taipei\", \"Asia\"),\n",
    "    (\"Turkey\", \"Asia\"),\n",
    "    (\"Greece\", \"Europe\"),\n",
    "    (\"Uganda\", \"Africa\"),\n",
    "    (\"Ecuador\", \"South America\"),\n",
    "    (\"Ireland\", \"Europe\"),\n",
    "    (\"Israel\", \"Asia\"),\n",
    "    (\"Qatar\", \"Asia\"),\n",
    "    (\"Bahamas\", \"North America\"),\n",
    "    (\"Kosovo\", \"Europe\"),\n",
    "    (\"Ukraine\", \"Europe\"),\n",
    "    (\"Belarus\", \"Europe\"),\n",
    "    (\"Romania\", \"Europe\"),\n",
    "    (\"Venezuela\", \"South America\"),\n",
    "    (\"India\", \"Asia\"),\n",
    "    (\"Hong Kong, China\", \"Asia\"),\n",
    "    (\"Philippines\", \"Asia\"),\n",
    "    (\"Slovakia\", \"Europe\"),\n",
    "    (\"South Africa\", \"Africa\"),\n",
    "    (\"Austria\", \"Europe\"),\n",
    "    (\"Egypt\", \"Africa\"),\n",
    "    (\"Indonesia\", \"Asia\"),\n",
    "    (\"Ethiopia\", \"Africa\"),\n",
    "    (\"Portugal\", \"Europe\"),\n",
    "    (\"Tunisia\", \"Africa\"),\n",
    "    (\"Estonia\", \"Europe\"),\n",
    "    (\"Fiji\", \"Oceania\"),\n",
    "    (\"Latvia\", \"Europe\"),\n",
    "    (\"Thailand\", \"Asia\"),\n",
    "    (\"Bermuda\", \"North America\"),\n",
    "    (\"Morocco\", \"Africa\"),\n",
    "    (\"Puerto Rico\", \"North America\"),\n",
    "    (\"Colombia\", \"South America\"),\n",
    "    (\"Azerbaijan\", \"Asia\"),\n",
    "    (\"Dominican Republic\", \"North America\"),\n",
    "    (\"Armenia\", \"Asia\"),\n",
    "    (\"Kyrgyzstan\", \"Asia\"),\n",
    "    (\"Mongolia\", \"Asia\"),\n",
    "    (\"Argentina\", \"South America\"),\n",
    "    (\"San Marino\", \"Europe\"),\n",
    "    (\"Jordan\", \"Asia\"),\n",
    "    (\"Malaysia\", \"Asia\"),\n",
    "    (\"Nigeria\", \"Africa\"),\n",
    "    (\"Bahrain\", \"Asia\"),\n",
    "    (\"Saudi Arabia\", \"Asia\"),\n",
    "    (\"Lithuania\", \"Europe\"),\n",
    "    (\"North Macedonia\", \"Europe\"),\n",
    "    (\"Namibia\", \"Africa\"),\n",
    "    (\"Turkmenistan\", \"Asia\"),\n",
    "    (\"Kazakhstan\", \"Asia\"),\n",
    "    (\"Mexico\", \"North America\"),\n",
    "    (\"Finland\", \"Europe\"),\n",
    "    (\"Botswana\", \"Africa\"),\n",
    "    (\"Burkina Faso\", \"Africa\"),\n",
    "    (\"CÃ´te d'Ivoire\", \"Africa\"),\n",
    "    (\"Ghana\", \"Africa\"),\n",
    "    (\"Grenada\", \"North America\"),\n",
    "    (\"Kuwait\", \"Asia\"),\n",
    "    (\"Republic of Moldova\", \"Europe\"),\n",
    "    (\"Syrian Arab Republic\", \"Asia\"),\n",
    "]\n",
    "\n",
    "# Create a DataFrame for continent mapping\n",
    "continent_mapping_df = spark.createDataFrame(continent_data, [\"Team Country\", \"Continent\"])\n",
    "\n",
    "# Save the Continent Mapping DataFrame to ADLS (optional)\n",
    "continent_mapping_path = \"/mnt/tokyoolympic/raw_data/continent_mapping.csv\"\n",
    "continent_mapping_df.write.format(\"parquet\").mode(\"overwrite\").save(continent_mapping_path)\n",
    "\n",
    "# Display the Continent Mapping DataFrame\n",
    "continent_mapping_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8ead22c-177d-497f-9c9b-e82fb75ccf8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**\"Overall Performance Analysis By Continent\" Tranformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6f0b9f5-95f0-427d-8b9b-892f3a6c6ab0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, sum as _sum, expr\n",
    "\n",
    "# Load the required tables\n",
    "medals_path = \"/mnt/tokyoolympic/raw_data/medals.csv\"\n",
    "athletes_path = \"/mnt/tokyoolympic/raw_data/athletes.csv\"\n",
    "continent_mapping_path = \"/mnt/tokyoolympic/raw_data/continent_mapping.csv\"\n",
    "\n",
    "medals_df = spark.read.format(\"csv\").option(\"header\",True).load(medals_path)\n",
    "athletes_df = spark.read.format(\"csv\").option(\"header\",True).load(athletes_path)\n",
    "continent_mapping_df = spark.read.format(\"csv\").option(\"header\",True).load(continent_mapping_path)\n",
    "\n",
    "# Step 1: Join medals and continent mapping to associate continents with medals\n",
    "medals_with_continents = medals_df.join(\n",
    "    continent_mapping_df,\n",
    "    medals_df[\"TeamCountry\"] == continent_mapping_df[\"Team Country\"],\n",
    "    how=\"inner\"\n",
    ").select(\n",
    "    col(\"Continent\"),\n",
    "    col(\"Gold\"),\n",
    "    col(\"Silver\"),\n",
    "    col(\"Bronze\"),\n",
    "    col(\"Total\").alias(\"TotalMedals\")\n",
    ")\n",
    "\n",
    "# Step 2: Aggregate medal counts by continent\n",
    "continent_medals = medals_with_continents.groupBy(\"Continent\").agg(\n",
    "    _sum(\"Gold\").alias(\"TotalGold\"),\n",
    "    _sum(\"Silver\").alias(\"TotalSilver\"),\n",
    "    _sum(\"Bronze\").alias(\"TotalBronze\"),\n",
    "    _sum(\"TotalMedals\").alias(\"TotalMedalsByContinent\")\n",
    ")\n",
    "\n",
    "# Step 3: Join athletes with continent mapping for participation data\n",
    "athletes_with_continents = athletes_df.join(\n",
    "    continent_mapping_df,\n",
    "    athletes_df.Country == continent_mapping_df[\"Team Country\"],\n",
    "    how=\"inner\"\n",
    ").select(\n",
    "    col(\"Continent\"),\n",
    "    col(\"PersonName\")\n",
    ")\n",
    "\n",
    "# Step 4: Calculate athlete participation by continent\n",
    "continent_participation = athletes_with_continents.groupBy(\"Continent\").agg(\n",
    "    count(\"PersonName\").alias(\"TotalAthletes\")\n",
    ")\n",
    "\n",
    "# Step 5: Combine medal and participation data to calculate efficiency\n",
    "continent_performance = continent_medals.join(\n",
    "    continent_participation,\n",
    "    \"Continent\",\n",
    "    how=\"inner\"\n",
    ").withColumn(\n",
    "    \"MedalsPerAthlete\", expr(\"ROUND(TotalMedalsByContinent / TotalAthletes, 2)\")\n",
    ")\n",
    "\n",
    "# Save the transformed data back to ADLS\n",
    "continent_performance_path = \"/mnt/tokyoolympic/transformed_data/continent_performance\"\n",
    "\n",
    "continent_performance.write.format(\"parquet\").mode(\"overwrite\").save(continent_performance_path)\n",
    "\n",
    "# Display the results\n",
    "continent_performance.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-08-08 16:30:45",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}